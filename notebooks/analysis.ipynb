{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9ef8b64d6d2f1d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Carseats Sales Prediction using Tree-Based Models\n",
    "\n",
    "## Objective\n",
    "The goal of this project is to predict numerical sales values using:\n",
    "- Regression Trees\n",
    "- Pruned Regression Trees (via Cross-Validation)\n",
    "- Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd6b5ef6724e6",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.data_loader import load_carseats\n",
    "from src.preprocess import preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83b3b596e64c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Prepare data\n",
    "\n",
    "df = load_carseats(\"../data/Carseats.csv\")\n",
    "df = preprocess(df)\n",
    "\n",
    "X = df.drop(\"Sales\", axis=1)\n",
    "y = df[\"Sales\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b616ebc2-5b0e-4fd1-9c52-30b9c80a7c98",
   "metadata": {},
   "source": [
    "## Regression Tree\n",
    "\n",
    "We first fit a regression tree on the training data and evaluate its performance on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db6b0c90-68b8-4fc6-9092-cc0ddac0a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev-nazari/miniconda3/envs/ML_lab/lib/python3.13/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.093451666666666"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import load\n",
    "\n",
    "tree = load(\"../models/tree_model.joblib\")\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "mse_tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb2253a-dd9e-4c16-bfa7-03fdc4dbd56a",
   "metadata": {},
   "source": [
    "## Pruned Regression Tree\n",
    "\n",
    "Using cost-complexity pruning and cross-validation, we selected an optimal tree size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2774430c-da14-4fe3-9db4-1f2852198c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev-nazari/miniconda3/envs/ML_lab/lib/python3.13/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.615269382245914"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_tree = load(\"../models/pruned_tree_model.joblib\")\n",
    "y_pred_pruned = pruned_tree.predict(X_test)\n",
    "\n",
    "mse_pruned = mean_squared_error(y_test, y_pred_pruned)\n",
    "mse_pruned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c30d2-efc3-497f-9b40-6477d8d97816",
   "metadata": {},
   "source": [
    "## Bagging Analysis\n",
    "Bagging aggregates multiple trees trained on bootstrap samples.\n",
    "This reduces variance and usually improves predictive performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ff81edc-3771-4d9f-88e4-02d3203df09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev-nazari/miniconda3/envs/ML_lab/lib/python3.13/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/dev-nazari/miniconda3/envs/ML_lab/lib/python3.13/site-packages/sklearn/base.py:463: InconsistentVersionWarning: Trying to unpickle estimator BaggingRegressor from version 1.7.2 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.5759218064999994"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging = load(\"../models/bagging_model.joblib\")\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "\n",
    "mse_bagging = mean_squared_error(y_test, y_pred_bagging)\n",
    "mse_bagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "954faf2e-9c25-4cd2-b475-7373ef5dc832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regression Tree</td>\n",
       "      <td>6.093452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>4.615269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>2.575922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Test MSE\n",
       "0  Regression Tree  6.093452\n",
       "1      Pruned Tree  4.615269\n",
       "2          Bagging  2.575922"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"Model\": [\"Regression Tree\", \"Pruned Tree\", \"Bagging\"],\n",
    "    \"Test MSE\": [mse_tree, mse_pruned, mse_bagging]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983296a1-c9f8-434c-bcda-b37ab74394e1",
   "metadata": {},
   "source": [
    "## Model Performance Analysis\n",
    "\n",
    "We evaluated three tree-based regression models on the same train–test split using **Mean Squared Error (MSE)** as the primary evaluation metric.  \n",
    "Lower MSE values indicate better predictive performance.\n",
    "\n",
    "| Model            | Test MSE |\n",
    "|------------------|----------|\n",
    "| Regression Tree  | 6.093452 |\n",
    "| Pruned Tree      | 4.615269 |\n",
    "| Bagging          | 2.575922 |\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Regression Tree (Baseline)\n",
    "\n",
    "The **unpruned regression tree** exhibits the weakest performance among the evaluated models.\n",
    "\n",
    "### Interpretation\n",
    "- Single decision trees are **high-variance** models.\n",
    "- They tend to overfit the training data by capturing noise.\n",
    "- As a result, generalization to unseen data is limited.\n",
    "\n",
    "### Conclusion\n",
    "This model is useful as a **baseline**, but its relatively high test MSE indicates that it is not suitable for reliable prediction on its own.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Pruned Tree (Improved Bias–Variance Tradeoff)\n",
    "\n",
    "Applying **cost-complexity pruning** reduces the test MSE from **6.09 to 4.62**, representing an improvement of approximately **24%**.\n",
    "\n",
    "### Interpretation\n",
    "- Pruning removes splits that do not contribute meaningfully to predictive performance.\n",
    "- This reduces model variance while slightly increasing bias.\n",
    "- The net effect is improved generalization.\n",
    "\n",
    "### Key Insight\n",
    "The performance gain confirms that the original regression tree was **overfitting**, and pruning helped control model complexity.\n",
    "\n",
    "### Conclusion\n",
    "Pruning is an essential step when using decision trees in practice, but it does not fully address the variance issue inherent to tree-based models.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Bagging (Ensemble Learning)\n",
    "\n",
    "Bagging delivers the strongest performance, reducing test MSE to **2.58**, which corresponds to:\n",
    "- ~44% improvement over the pruned tree\n",
    "- ~58% improvement over the unpruned tree\n",
    "\n",
    "### Interpretation\n",
    "- Bagging aggregates predictions from multiple trees trained on bootstrapped samples.\n",
    "- This averaging process significantly reduces variance.\n",
    "- Decision trees benefit greatly from bagging due to their instability.\n",
    "\n",
    "### Theoretical Justification\n",
    "This result aligns with learning theory:\n",
    "> Ensemble methods improve predictive accuracy by stabilizing high-variance base learners.\n",
    "\n",
    "---\n",
    "\n",
    "## Comparative Summary\n",
    "\n",
    "| Aspect          | Regression Tree | Pruned Tree | Bagging |\n",
    "|-----------------|-----------------|-------------|---------|\n",
    "| Overfitting     | High            | Moderate    | Low     |\n",
    "| Bias            | Low             | Slightly Higher | Low |\n",
    "| Variance        | Very High       | Reduced     | Very Low |\n",
    "| Generalization  | Poor            | Improved    | Best    |\n",
    "\n",
    "---\n",
    "\n",
    "## Final Conclusion\n",
    "\n",
    "1. **Controlling model complexity is necessary**  \n",
    "   Pruning improves generalization but has limited impact on variance reduction.\n",
    "\n",
    "2. **Variance reduction is the key driver of performance**  \n",
    "   Bagging effectively addresses the primary weakness of decision trees.\n",
    "\n",
    "3. **Recommended model**  \n",
    "   The **Bagging model** is the most suitable choice for deployment due to its superior generalization performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Project Takeaway\n",
    "\n",
    "This experiment demonstrates how moving from a single decision tree to a pruned tree and finally to an ensemble method leads to syste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce7904-1201-4e1c-9c9b-619d863b69b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
